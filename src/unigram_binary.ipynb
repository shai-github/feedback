{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0366fabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:56:00.431556Z",
     "iopub.status.busy": "2022-02-28T00:56:00.426446Z",
     "iopub.status.idle": "2022-02-28T00:56:02.317691Z",
     "shell.execute_reply": "2022-02-28T00:56:02.316843Z",
     "shell.execute_reply.started": "2022-02-27T22:51:05.717158Z"
    },
    "papermill": {
     "duration": 1.934762,
     "end_time": "2022-02-28T00:56:02.317901",
     "exception": false,
     "start_time": "2022-02-28T00:56:00.383139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.data\n",
    "from collections import Counter\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from scipy import sparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9446e853",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-28T00:56:02.403009Z",
     "iopub.status.busy": "2022-02-28T00:56:02.402230Z",
     "iopub.status.idle": "2022-02-28T00:57:40.540288Z",
     "shell.execute_reply": "2022-02-28T00:57:40.539593Z",
     "shell.execute_reply.started": "2022-02-27T22:51:07.350728Z"
    },
    "papermill": {
     "duration": 98.182513,
     "end_time": "2022-02-28T00:57:40.540546",
     "exception": false,
     "start_time": "2022-02-28T00:56:02.358033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wp_tokenizer = WordPunctTokenizer()\n",
    "counter = Counter()\n",
    "counter.update(['<pad>', '<unk>'])\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/feedback-prize-2021/train'):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        with open(full_path) as f:\n",
    "            data = f.read()\n",
    "        tokens = wp_tokenizer.tokenize(data.lower())\n",
    "        counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ff7e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:57:40.634625Z",
     "iopub.status.busy": "2022-02-28T00:57:40.629087Z",
     "iopub.status.idle": "2022-02-28T00:57:40.670112Z",
     "shell.execute_reply": "2022-02-28T00:57:40.670679Z",
     "shell.execute_reply.started": "2022-02-27T22:52:21.310548Z"
    },
    "papermill": {
     "duration": 0.094327,
     "end_time": "2022-02-28T00:57:40.670888",
     "exception": false,
     "start_time": "2022-02-28T00:57:40.576561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size before frequency filtering: 52579\n",
      "Vocab size after frequency filtering: 13679\n"
     ]
    }
   ],
   "source": [
    "# VOCAB CONSTRUCTION\n",
    "\n",
    "print(f\"Vocab size before frequency filtering: {len(counter)}\")\n",
    "\n",
    "vocab = {}\n",
    "i = 0\n",
    "for word, count in counter.items():\n",
    "    if (count >= 5 or word in ['<pad>', '<unk>']):\n",
    "        vocab[word] = i\n",
    "        i += 1\n",
    "\n",
    "print(f\"Vocab size after frequency filtering: {len(vocab)}\")\n",
    "output_filepath = ('/kaggle/working/unigram_vocab.json')\n",
    "json.dump(vocab, open(output_filepath, mode='w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5f8364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:57:40.753411Z",
     "iopub.status.busy": "2022-02-28T00:57:40.752355Z",
     "iopub.status.idle": "2022-02-28T00:58:54.498025Z",
     "shell.execute_reply": "2022-02-28T00:58:54.498780Z",
     "shell.execute_reply.started": "2022-02-27T22:52:21.367433Z"
    },
    "papermill": {
     "duration": 73.787877,
     "end_time": "2022-02-28T00:58:54.499016",
     "exception": false,
     "start_time": "2022-02-28T00:57:40.711139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURES + LABELS CONSTRUCTION - NEED ONE FOR EACH DISCOURSE TYPE\n",
    "\n",
    "train_data = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "tot_lines = 0\n",
    "for index, row in train_data.iterrows():\n",
    "    lines = sent_tokenizer.tokenize(row['discourse_text']) \n",
    "    tot_lines += len(lines)\n",
    "\n",
    "# CLAIM, CONCLUDING STATEMENT, COUNTERCLAIM, EVIDENCE, LEAD, POSITION, REBUTTAL  \n",
    "claim_labels_array = [0]*tot_lines\n",
    "con_stat_labels_array = [0]*tot_lines\n",
    "coun_claim_labels_array = [0]*tot_lines\n",
    "evidence_labels_array = [0]*tot_lines\n",
    "lead_labels_array = [0]*tot_lines\n",
    "position_labels_array = [0]*tot_lines\n",
    "rebuttal_labels_array = [0]*tot_lines\n",
    "\n",
    "feat_array = np.zeros((tot_lines, len(vocab)))\n",
    "\n",
    "line_idx = 0\n",
    "for index, row in train_data.iterrows():\n",
    "    lines = sent_tokenizer.tokenize(row['discourse_text'])\n",
    "    for line in lines:\n",
    "        if row['discourse_type'] == 'Claim':\n",
    "            claim_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Concluding Statement':\n",
    "            con_stat_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Counterclaim':\n",
    "            coun_claim_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Evidence':\n",
    "            evidence_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Lead':\n",
    "            lead_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Position':\n",
    "            position_labels_array[line_idx] = 1\n",
    "        elif row['discourse_type'] == 'Rebuttal':\n",
    "            rebuttal_labels_array[line_idx] = 1\n",
    "        \n",
    "        tokens = wp_tokenizer.tokenize(line.lower())\n",
    "\n",
    "        for tok in tokens:\n",
    "            try:\n",
    "                index = vocab[tok]\n",
    "            except KeyError:\n",
    "                index = vocab['<unk>']\n",
    "            feat_array[line_idx][index] = 1 \n",
    "        \n",
    "        line_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095a58f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:58:54.580170Z",
     "iopub.status.busy": "2022-02-28T00:58:54.579116Z",
     "iopub.status.idle": "2022-02-28T00:58:54.642138Z",
     "shell.execute_reply": "2022-02-28T00:58:54.641474Z",
     "shell.execute_reply.started": "2022-02-28T00:41:57.397192Z"
    },
    "papermill": {
     "duration": 0.107247,
     "end_time": "2022-02-28T00:58:54.642295",
     "exception": false,
     "start_time": "2022-02-28T00:58:54.535048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST LOADING & TOKENIZATION\n",
    "\n",
    "test_dir = '/kaggle/input/feedback-prize-2021/test'\n",
    "\n",
    "def test_sent(test_file):\n",
    "    '''\n",
    "    generates tokenized sentences for test data with corresponding list of essay IDs\n",
    "    '''\n",
    "    \n",
    "    full_path = os.path.join(test_dir, test_file)\n",
    "    with open(full_path) as f:\n",
    "        data = f.read()\n",
    "    lines = sent_tokenizer.tokenize(data.lower())\n",
    "    \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        tok_line = wp_tokenizer.tokenize(line)\n",
    "        tokens.append(tok_line)\n",
    "        \n",
    "    lines_len = len(lines)\n",
    "    id_list = [test_file.replace('.txt', '')] * lines_len\n",
    "    \n",
    "    return tokens, id_list, lines\n",
    "\n",
    "test1 = test_sent('0FB0700DAF44.txt')\n",
    "test2 = test_sent('18409261F5C2.txt')\n",
    "test3 = test_sent('D46BCB48440A.txt')\n",
    "test4 = test_sent('D72CB1C11673.txt')\n",
    "test5 = test_sent('DF920E0A7337.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d9cb7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:58:54.722320Z",
     "iopub.status.busy": "2022-02-28T00:58:54.721534Z",
     "iopub.status.idle": "2022-02-28T00:58:54.724062Z",
     "shell.execute_reply": "2022-02-28T00:58:54.724597Z",
     "shell.execute_reply.started": "2022-02-28T00:41:23.511199Z"
    },
    "papermill": {
     "duration": 0.046941,
     "end_time": "2022-02-28T00:58:54.724824",
     "exception": false,
     "start_time": "2022-02-28T00:58:54.677883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_binary(test_tokens):\n",
    "    '''\n",
    "    docstring\n",
    "    '''\n",
    "    \n",
    "    feat_array = np.zeros((len(test_tokens), len(vocab)))\n",
    "    \n",
    "    for line in test_tokens:\n",
    "        for tok in line:\n",
    "            try:\n",
    "                index = vocab[tok]\n",
    "            except KeyError:\n",
    "                index = vocab['<unk>']\n",
    "            feat_array[test_tokens.index(line)][index] = 1    \n",
    "\n",
    "    return feat_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1490654a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:58:54.802313Z",
     "iopub.status.busy": "2022-02-28T00:58:54.801568Z",
     "iopub.status.idle": "2022-02-28T00:59:38.766031Z",
     "shell.execute_reply": "2022-02-28T00:59:38.765194Z",
     "shell.execute_reply.started": "2022-02-27T22:53:30.472433Z"
    },
    "papermill": {
     "duration": 44.006047,
     "end_time": "2022-02-28T00:59:38.766210",
     "exception": false,
     "start_time": "2022-02-28T00:58:54.760163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_sparse_matrix = sparse.csr_matrix(feat_array)\n",
    "sparse.save_npz('/kaggle/working/unigram_binary_features.npz', features_sparse_matrix)\n",
    "np.savez('/kaggle/working/claim_labels.npz', claim_labels_array)\n",
    "np.savez('/kaggle/working/con_stat_labels.npz', con_stat_labels_array)\n",
    "np.savez('/kaggle/working/coun_claim_labels.npz', coun_claim_labels_array)\n",
    "np.savez('/kaggle/working/evidence_labels.npz', evidence_labels_array)\n",
    "np.savez('/kaggle/working/lead_labels.npz', lead_labels_array)\n",
    "np.savez('/kaggle/working/position_labels.npz', position_labels_array)\n",
    "np.savez('/kaggle/working/rebuttal_labels.npz', rebuttal_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2efef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:59:38.848104Z",
     "iopub.status.busy": "2022-02-28T00:59:38.846853Z",
     "iopub.status.idle": "2022-02-28T00:59:39.194081Z",
     "shell.execute_reply": "2022-02-28T00:59:39.194781Z",
     "shell.execute_reply.started": "2022-02-27T22:54:14.039310Z"
    },
    "papermill": {
     "duration": 0.392755,
     "end_time": "2022-02-28T00:59:39.195057",
     "exception": false,
     "start_time": "2022-02-28T00:59:38.802302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE THIS BLOCK WHEN COMMITTING\n",
    "\n",
    "train_features = sparse.load_npz('/kaggle/working/unigram_binary_features.npz')\n",
    "claim_labels = np.load('/kaggle/working/claim_labels.npz')['arr_0']\n",
    "con_stat_labels = np.load('/kaggle/working/con_stat_labels.npz')['arr_0']\n",
    "coun_claim_labels = np.load('/kaggle/working/coun_claim_labels.npz')['arr_0']\n",
    "evidence_labels = np.load('/kaggle/working/evidence_labels.npz')['arr_0']\n",
    "lead_labels = np.load('/kaggle/working/lead_labels.npz')['arr_0']\n",
    "position_labels = np.load('/kaggle/working/position_labels.npz')['arr_0']\n",
    "rebuttal_labels = np.load('/kaggle/working/rebuttal_labels.npz')['arr_0']\n",
    "vocab = json.load(open('/kaggle/working/unigram_vocab.json'))\n",
    "\n",
    "\n",
    "# USE THIS BLOCK WHEN INITIALLY LOADING FROM SAVE\n",
    "                       \n",
    "#train_features = sparse.load_npz('../input/nlp35100-unigrambinary/unigram_binary_features.npz')\n",
    "#claim_labels = np.load('../input/nlp35100-unigrambinary/claim_labels.npz')['arr_0']\n",
    "#con_stat_labels = np.load('../input/nlp35100-unigrambinary/con_stat_labels.npz')['arr_0']\n",
    "#coun_claim_labels = np.load('../input/nlp35100-unigrambinary/coun_claim_labels.npz')['arr_0']\n",
    "#evidence_labels = np.load('../input/nlp35100-unigrambinary/evidence_labels.npz')['arr_0']\n",
    "#lead_labels = np.load('../input/nlp35100-unigrambinary/lead_labels.npz')['arr_0']\n",
    "#position_labels = np.load('../input/nlp35100-unigrambinary/position_labels.npz')['arr_0']\n",
    "#rebuttal_labels = np.load('../input/nlp35100-unigrambinary/rebuttal_labels.npz')['arr_0']\n",
    "#vocab = json.load(open('../input/nlp35100-unigrambinary/unigram_vocab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b300a5cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:59:39.277499Z",
     "iopub.status.busy": "2022-02-28T00:59:39.276277Z",
     "iopub.status.idle": "2022-02-28T00:59:39.279814Z",
     "shell.execute_reply": "2022-02-28T00:59:39.279178Z",
     "shell.execute_reply.started": "2022-02-27T22:54:14.363150Z"
    },
    "papermill": {
     "duration": 0.048697,
     "end_time": "2022-02-28T00:59:39.279979",
     "exception": false,
     "start_time": "2022-02-28T00:59:39.231282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_important_weights(weights, words):\n",
    "    \"\"\"\n",
    "    Print important pairs of weights and words.\n",
    "    # Parameters\n",
    "    weights : `Iterable`, required.\n",
    "        Weights from a learned model.\n",
    "    words : `Iterable`, required.\n",
    "        Word types of the vocabulary.  \n",
    "        It must be true that `len(weights) == len(words)`.\n",
    "    # Returns\n",
    "        `None`\n",
    "    \"\"\"\n",
    "\n",
    "    def print_pairs(pairs):\n",
    "        for weight, word in pairs:\n",
    "            print(\"{: .4f} | {}\".format(weight, word))\n",
    "\n",
    "    assert len(weights) == len(words)\n",
    "    pairs = list(zip(weights, words))\n",
    "    pairs = sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "    print(\"Most positive words:\")\n",
    "    print_pairs(pairs[:10])\n",
    "    print(\"\\nMost negative words:\")\n",
    "    print_pairs(reversed(pairs[-10:]))\n",
    "\n",
    "    #pairs = list(zip(abs(weights), words))\n",
    "    #pairs = sorted(pairs, key=lambda x: x[0], reverse=False)\n",
    "    #print(\"\\nMost neutral words:\")\n",
    "    #print_pairs(pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e42089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T00:59:39.360142Z",
     "iopub.status.busy": "2022-02-28T00:59:39.358592Z",
     "iopub.status.idle": "2022-02-28T01:00:10.489576Z",
     "shell.execute_reply": "2022-02-28T01:00:10.488966Z",
     "shell.execute_reply.started": "2022-02-27T22:54:14.372101Z"
    },
    "papermill": {
     "duration": 31.17456,
     "end_time": "2022-02-28T01:00:10.489750",
     "exception": false,
     "start_time": "2022-02-28T00:59:39.315190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim Train Accuracy: 0.8247047315411926\n",
      "Claim Train F1 Score: 0.5019728264598916\n"
     ]
    }
   ],
   "source": [
    "# CLAIM MODEL\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "lr_claim = LogisticRegression(solver='sag', class_weight = {0:0.25, 1:0.75}).fit(train_features, claim_labels)\n",
    "probs_claim = lr_claim.predict_proba(train_features)\n",
    "train_pred_claim = lr_claim.predict(train_features)\n",
    "\n",
    "print(\"Claim Train Accuracy:\", accuracy_score(claim_labels, train_pred_claim))\n",
    "print(\"Claim Train F1 Score:\", f1_score(claim_labels, train_pred_claim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39c15c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:00:10.568577Z",
     "iopub.status.busy": "2022-02-28T01:00:10.567649Z",
     "iopub.status.idle": "2022-02-28T01:00:10.608429Z",
     "shell.execute_reply": "2022-02-28T01:00:10.607761Z",
     "shell.execute_reply.started": "2022-02-27T22:54:38.027967Z"
    },
    "papermill": {
     "duration": 0.083499,
     "end_time": "2022-02-28T01:00:10.608699",
     "exception": false,
     "start_time": "2022-02-28T01:00:10.525200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 2.4905 | secondly\n",
      " 2.0561 | firstly\n",
      " 1.7618 | thirdly\n",
      " 1.5203 | cancelled\n",
      " 1.4232 | commence\n",
      " 1.3994 | foremost\n",
      " 1.3886 | lastly\n",
      " 1.2517 | darkness\n",
      " 1.2383 | poplular\n",
      " 1.1898 | frist\n",
      "\n",
      "Most negative words:\n",
      "-2.3594 | .\"\n",
      "-2.3575 | ?\n",
      "-2.3287 | ?\"\n",
      "-2.3255 | !\"\n",
      "-2.3250 | \".\n",
      "-2.2342 | .\".\n",
      "-2.1773 | generic_name\n",
      "-2.0520 | argue\n",
      "-2.0478 | conclusion\n",
      "-1.9764 | %.\n"
     ]
    }
   ],
   "source": [
    "probs_claim = probs_claim[:,lr_claim.classes_ == 1]\n",
    "weights_claim = lr_claim.coef_[0]\n",
    "print_important_weights(weights=weights_claim, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b269d813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:00:10.690335Z",
     "iopub.status.busy": "2022-02-28T01:00:10.689486Z",
     "iopub.status.idle": "2022-02-28T01:00:40.264005Z",
     "shell.execute_reply": "2022-02-28T01:00:40.263202Z",
     "shell.execute_reply.started": "2022-02-27T22:54:38.067827Z"
    },
    "papermill": {
     "duration": 29.618367,
     "end_time": "2022-02-28T01:00:40.264226",
     "exception": false,
     "start_time": "2022-02-28T01:00:10.645859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement Train Accuracy: 0.8564294857860542\n",
      "Concluding Statement Train F1 Score: 0.44305724725943973\n"
     ]
    }
   ],
   "source": [
    "# CONCLUDING STATEMENT MODEL\n",
    "\n",
    "lr_con_stat = LogisticRegression(solver='sag', class_weight = {0:0.25, 1:0.75}).fit(train_features, con_stat_labels)\n",
    "probs_con_stat = lr_con_stat.predict_proba(train_features)\n",
    "train_pred_con_stat = lr_con_stat.predict(train_features)\n",
    "\n",
    "print(\"Concluding Statement Train Accuracy:\", accuracy_score(con_stat_labels, train_pred_con_stat))\n",
    "print(\"Concluding Statement Train F1 Score:\", f1_score(con_stat_labels, train_pred_con_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f08877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:00:40.347646Z",
     "iopub.status.busy": "2022-02-28T01:00:40.346332Z",
     "iopub.status.idle": "2022-02-28T01:00:40.376063Z",
     "shell.execute_reply": "2022-02-28T01:00:40.375208Z",
     "shell.execute_reply.started": "2022-02-27T22:55:01.264699Z"
    },
    "papermill": {
     "duration": 0.072904,
     "end_time": "2022-02-28T01:00:40.376240",
     "exception": false,
     "start_time": "2022-02-28T01:00:40.303336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 3.4369 | conclusion\n",
      " 2.8127 | conclution\n",
      " 2.5220 | conclude\n",
      " 2.2550 | !\n",
      " 2.1570 | inconclusion\n",
      " 2.1218 | thank\n",
      " 2.1136 | !!\n",
      " 2.0628 | hope\n",
      " 1.9719 | .\n",
      " 1.9623 | wrap\n",
      "\n",
      "Most negative words:\n",
      "-1.6745 | loud\n",
      "-1.6116 | dear\n",
      "-1.5694 | example\n",
      "-1.5428 | wondered\n",
      "-1.4682 | 70\n",
      "-1.3848 | residents\n",
      "-1.3336 | displays\n",
      "-1.3319 | instance\n",
      "-1.2905 | bmw\n",
      "-1.2852 | english\n"
     ]
    }
   ],
   "source": [
    "probs_con_stat = probs_con_stat[:,lr_con_stat.classes_ == 1]\n",
    "weights_con_stat = lr_con_stat.coef_[0]\n",
    "print_important_weights(weights=weights_con_stat, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e4540c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:00:40.460149Z",
     "iopub.status.busy": "2022-02-28T01:00:40.459285Z",
     "iopub.status.idle": "2022-02-28T01:01:09.261335Z",
     "shell.execute_reply": "2022-02-28T01:01:09.262836Z",
     "shell.execute_reply.started": "2022-02-27T22:55:01.293340Z"
    },
    "papermill": {
     "duration": 28.8492,
     "end_time": "2022-02-28T01:01:09.263209",
     "exception": false,
     "start_time": "2022-02-28T01:00:40.414009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim Statement Train Accuracy: 0.963550346593242\n",
      "Counterclaim Statement Train F1 Score: 0.38917278016696183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# COUNTERCLAIM STATEMENT MODEL\n",
    "\n",
    "lr_coun_claim = LogisticRegression(solver='sag', class_weight = {0:0.1, 1:0.9}).fit(train_features, coun_claim_labels)\n",
    "probs_coun_claim = lr_coun_claim.predict_proba(train_features)\n",
    "train_pred_coun_claim = lr_coun_claim.predict(train_features)\n",
    "\n",
    "print(\"Counterclaim Statement Train Accuracy:\", accuracy_score(coun_claim_labels, train_pred_coun_claim))\n",
    "print(\"Counterclaim Statement Train F1 Score:\", f1_score(coun_claim_labels, train_pred_coun_claim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e1c798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:01:09.348051Z",
     "iopub.status.busy": "2022-02-28T01:01:09.347161Z",
     "iopub.status.idle": "2022-02-28T01:01:09.374418Z",
     "shell.execute_reply": "2022-02-28T01:01:09.375013Z",
     "shell.execute_reply.started": "2022-02-27T22:55:23.738135Z"
    },
    "papermill": {
     "duration": 0.069839,
     "end_time": "2022-02-28T01:01:09.375224",
     "exception": false,
     "start_time": "2022-02-28T01:01:09.305385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 2.9199 | argue\n",
      " 2.6585 | downside\n",
      " 2.1839 | critics\n",
      " 2.1756 | hand\n",
      " 2.0894 | argued\n",
      " 2.0776 | opponents\n",
      " 1.8324 | contrary\n",
      " 1.7972 | manufactors\n",
      " 1.7904 | argument\n",
      " 1.7889 | yes\n",
      "\n",
      "Most negative words:\n",
      "-1.7578 | conclusion\n",
      "-1.6992 | imagine\n",
      "-1.6211 | !\n",
      "-1.4814 | smog\n",
      "-1.4601 | helped\n",
      "-1.4326 | cowboys\n",
      "-1.4074 | math\n",
      "-1.3594 | .\n",
      "-1.3520 | happier\n",
      "-1.2901 | america\n"
     ]
    }
   ],
   "source": [
    "probs_coun_claim = probs_coun_claim[:,lr_coun_claim.classes_ == 1]\n",
    "weights_coun_claim = lr_coun_claim.coef_[0]\n",
    "print_important_weights(weights=weights_coun_claim, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e845d64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:01:09.460556Z",
     "iopub.status.busy": "2022-02-28T01:01:09.459506Z",
     "iopub.status.idle": "2022-02-28T01:01:35.585708Z",
     "shell.execute_reply": "2022-02-28T01:01:35.585009Z",
     "shell.execute_reply.started": "2022-02-27T22:55:23.764480Z"
    },
    "papermill": {
     "duration": 26.169612,
     "end_time": "2022-02-28T01:01:35.585872",
     "exception": false,
     "start_time": "2022-02-28T01:01:09.416260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence Train Accuracy: 0.740550201676207\n",
      "Evidence Train F1 Score: 0.7575415589838504\n"
     ]
    }
   ],
   "source": [
    "# EVIDENCE MODEL\n",
    "\n",
    "lr_ev = LogisticRegression(solver='sag').fit(train_features, evidence_labels)\n",
    "probs_ev = lr_ev.predict_proba(train_features)\n",
    "train_pred_ev = lr_ev.predict(train_features)\n",
    "\n",
    "print(\"Evidence Train Accuracy:\", accuracy_score(evidence_labels, train_pred_ev))\n",
    "print(\"Evidence Train F1 Score:\", f1_score(evidence_labels, train_pred_ev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "677467be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:01:35.676686Z",
     "iopub.status.busy": "2022-02-28T01:01:35.675619Z",
     "iopub.status.idle": "2022-02-28T01:01:35.703747Z",
     "shell.execute_reply": "2022-02-28T01:01:35.704302Z",
     "shell.execute_reply.started": "2022-02-27T22:55:46.494048Z"
    },
    "papermill": {
     "duration": 0.075405,
     "end_time": "2022-02-28T01:01:35.704527",
     "exception": false,
     "start_time": "2022-02-28T01:01:35.629122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 2.5322 | .''\n",
      " 2.5188 | .\".\n",
      " 2.5091 | '.\n",
      " 2.4813 | kennedy\n",
      " 2.3385 | %.\n",
      " 2.3367 | \".\n",
      " 2.2987 | .\"\n",
      " 2.2709 | !!!\n",
      " 2.2243 | .'\"\n",
      " 2.2065 | ?\".\n",
      "\n",
      "Most negative words:\n",
      "-2.4579 | conclution\n",
      "-1.9852 | conclusion\n",
      "-1.8098 | delt\n",
      "-1.7833 | opinon\n",
      "-1.7389 | ugh\n",
      "-1.7194 | wondered\n",
      "-1.7079 | airport\n",
      "-1.6752 | conculsion\n",
      "-1.6723 | march\n",
      "-1.6481 | ticked\n"
     ]
    }
   ],
   "source": [
    "probs_ev = probs_ev[:,lr_ev.classes_ == 1]\n",
    "weights_ev = lr_ev.coef_[0]\n",
    "print_important_weights(weights=weights_ev, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc349df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:01:35.798027Z",
     "iopub.status.busy": "2022-02-28T01:01:35.792972Z",
     "iopub.status.idle": "2022-02-28T01:02:06.134414Z",
     "shell.execute_reply": "2022-02-28T01:02:06.133506Z",
     "shell.execute_reply.started": "2022-02-27T22:55:46.519357Z"
    },
    "papermill": {
     "duration": 30.387993,
     "end_time": "2022-02-28T01:02:06.134659",
     "exception": false,
     "start_time": "2022-02-28T01:01:35.746666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Train Accuracy: 0.8986184575996908\n",
      "Lead Train F1 Score: 0.44523376837931605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# LEAD MODEL\n",
    "\n",
    "lr_lead = LogisticRegression(solver='sag', class_weight={0: 0.2, 1: 0.8}).fit(train_features, lead_labels)\n",
    "probs_lead = lr_lead.predict_proba(train_features)\n",
    "train_pred_lead = lr_lead.predict(train_features)\n",
    "\n",
    "print(\"Lead Train Accuracy:\", accuracy_score(lead_labels, train_pred_lead))\n",
    "print(\"Lead Train F1 Score:\", f1_score(lead_labels, train_pred_lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a283c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:02:06.220045Z",
     "iopub.status.busy": "2022-02-28T01:02:06.219215Z",
     "iopub.status.idle": "2022-02-28T01:02:06.246810Z",
     "shell.execute_reply": "2022-02-28T01:02:06.246019Z",
     "shell.execute_reply.started": "2022-02-27T22:56:09.031240Z"
    },
    "papermill": {
     "duration": 0.071275,
     "end_time": "2022-02-28T01:02:06.246981",
     "exception": false,
     "start_time": "2022-02-28T01:02:06.175706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 2.0452 | ?\n",
      " 1.9597 | wondered\n",
      " 1.9094 | !\"\n",
      " 1.7410 | debate\n",
      " 1.6770 | ?\"\n",
      " 1.6338 | ?.\n",
      " 1.6003 | debated\n",
      " 1.5961 | wondering\n",
      " 1.5748 | ?!\n",
      " 1.5351 | imagine\n",
      "\n",
      "Most negative words:\n",
      "-2.5531 | conclusion\n",
      "-2.0159 | mechanical\n",
      "-1.9859 | secondly\n",
      "-1.7549 | furthermore\n",
      "-1.6827 | certainty\n",
      "-1.6818 | lastly\n",
      "-1.5913 | markings\n",
      "-1.5499 | conclude\n",
      "-1.5490 | tie\n",
      "-1.5205 | concentrate\n"
     ]
    }
   ],
   "source": [
    "probs_lead = probs_lead[:,lr_lead.classes_ == 1]\n",
    "weights_lead = lr_lead.coef_[0]\n",
    "print_important_weights(weights=weights_lead, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6afa644a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:02:06.332834Z",
     "iopub.status.busy": "2022-02-28T01:02:06.332019Z",
     "iopub.status.idle": "2022-02-28T01:02:35.383253Z",
     "shell.execute_reply": "2022-02-28T01:02:35.384189Z",
     "shell.execute_reply.started": "2022-02-27T22:56:09.057837Z"
    },
    "papermill": {
     "duration": 29.096298,
     "end_time": "2022-02-28T01:02:35.384552",
     "exception": false,
     "start_time": "2022-02-28T01:02:06.288254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Train Accuracy: 0.9436695408545275\n",
      "Position Train F1 Score: 0.5445046628582588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# POSITION MODEL\n",
    "\n",
    "lr_position = LogisticRegression(solver='sag', class_weight={0: 0.2, 1: 0.8}).fit(train_features, position_labels)\n",
    "probs_position = lr_position.predict_proba(train_features)\n",
    "train_pred_position = lr_position.predict(train_features)\n",
    "\n",
    "print(\"Position Train Accuracy:\", accuracy_score(position_labels, train_pred_position))\n",
    "print(\"Position Train F1 Score:\", f1_score(position_labels, train_pred_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deffc281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:02:35.478846Z",
     "iopub.status.busy": "2022-02-28T01:02:35.477830Z",
     "iopub.status.idle": "2022-02-28T01:02:35.505441Z",
     "shell.execute_reply": "2022-02-28T01:02:35.506228Z",
     "shell.execute_reply.started": "2022-02-27T22:56:32.190177Z"
    },
    "papermill": {
     "duration": 0.077366,
     "end_time": "2022-02-28T01:02:35.506570",
     "exception": false,
     "start_time": "2022-02-28T01:02:35.429204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 1.6182 | advantages\n",
      " 1.5284 | valuble\n",
      " 1.5159 | valuable\n",
      " 1.4432 | aleins\n",
      " 1.4323 | benefit\n",
      " 1.4037 | landformation\n",
      " 1.3963 | auther\n",
      " 1.3594 | drives\n",
      " 1.3389 | sould\n",
      " 1.3332 | dear\n",
      "\n",
      "Most negative words:\n",
      "-2.3157 | ?\"\n",
      "-2.1477 | lastly\n",
      "-2.0113 | conclusion\n",
      "-1.9456 | secondly\n",
      "-1.8034 | .\"\n",
      "-1.7652 | example\n",
      "-1.7162 | finally\n",
      "-1.7086 | material\n",
      "-1.6499 | drunk\n",
      "-1.6150 | sleep\n"
     ]
    }
   ],
   "source": [
    "probs_position = probs_position[:,lr_position.classes_ == 1]\n",
    "weights_position = lr_position.coef_[0]\n",
    "print_important_weights(weights=weights_position, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65c5e3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:02:35.600588Z",
     "iopub.status.busy": "2022-02-28T01:02:35.599734Z",
     "iopub.status.idle": "2022-02-28T01:03:08.820883Z",
     "shell.execute_reply": "2022-02-28T01:03:08.820292Z",
     "shell.execute_reply.started": "2022-02-27T22:56:32.215895Z"
    },
    "papermill": {
     "duration": 33.270388,
     "end_time": "2022-02-28T01:03:08.821029",
     "exception": false,
     "start_time": "2022-02-28T01:02:35.550641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal Train Accuracy: 0.96456778494312\n",
      "Rebuttal Train F1 Score: 0.2653980971457186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# REBUTTAL MODEL\n",
    "\n",
    "lr_rebuttal = LogisticRegression(solver='sag', class_weight={0: 0.1, 1: 0.9}).fit(train_features, rebuttal_labels)\n",
    "probs_rebuttal = lr_rebuttal.predict_proba(train_features)\n",
    "train_pred_rebuttal = lr_rebuttal.predict(train_features)\n",
    "\n",
    "print(\"Rebuttal Train Accuracy:\", accuracy_score(rebuttal_labels, train_pred_rebuttal))\n",
    "print(\"Rebuttal Train F1 Score:\", f1_score(rebuttal_labels, train_pred_rebuttal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fa67a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:08.912594Z",
     "iopub.status.busy": "2022-02-28T01:03:08.911477Z",
     "iopub.status.idle": "2022-02-28T01:03:08.939198Z",
     "shell.execute_reply": "2022-02-28T01:03:08.939843Z",
     "shell.execute_reply.started": "2022-02-27T22:56:54.892398Z"
    },
    "papermill": {
     "duration": 0.077004,
     "end_time": "2022-02-28T01:03:08.940095",
     "exception": false,
     "start_time": "2022-02-28T01:03:08.863091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive words:\n",
      " 2.4530 | however\n",
      " 1.9514 | incorrect\n",
      " 1.7372 | but\n",
      " 1.6201 | true\n",
      " 1.5624 | chatting\n",
      " 1.5203 | briefly\n",
      " 1.4795 | pattern\n",
      " 1.4296 | presidant\n",
      " 1.4042 | valid\n",
      " 1.3824 | carpool\n",
      "\n",
      "Most negative words:\n",
      "-1.8272 | conclusion\n",
      "-1.6521 | lastly\n",
      "-1.6147 | advice\n",
      "-1.2989 | sad\n",
      "-1.2799 | advise\n",
      "-1.2784 | paris\n",
      "-1.2487 | limiting\n",
      "-1.2460 | dream\n",
      "-1.2239 | wonderful\n",
      "-1.2121 | secondly\n"
     ]
    }
   ],
   "source": [
    "probs_rebuttal = probs_rebuttal[:,lr_rebuttal.classes_ == 1]\n",
    "weights_rebuttal = lr_rebuttal.coef_[0]\n",
    "print_important_weights(weights=weights_rebuttal, words=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a436ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:09.033540Z",
     "iopub.status.busy": "2022-02-28T01:03:09.032290Z",
     "iopub.status.idle": "2022-02-28T01:03:12.818069Z",
     "shell.execute_reply": "2022-02-28T01:03:12.818614Z",
     "shell.execute_reply.started": "2022-02-27T22:56:54.919059Z"
    },
    "papermill": {
     "duration": 3.834576,
     "end_time": "2022-02-28T01:03:12.818817",
     "exception": false,
     "start_time": "2022-02-28T01:03:08.984241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 27937,\n",
       " 'Evidence': 170884,\n",
       " 'Concluding Statement': 43515,\n",
       " 'Counterclaim': 7619,\n",
       " 'Rebuttal': 5416,\n",
       " 'Position': 17726,\n",
       " 'Claim': 58127}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GO THROUGH MODELS\n",
    "\n",
    "model_dict = {0: 'Claim', 1: 'Concluding Statement', 2: 'Counterclaim', 3: 'Evidence', 4: 'Lead', 5: 'Position', 6:'Rebuttal'}\n",
    "tag_counts = {}\n",
    "output_labels = []\n",
    "\n",
    "all_probs = np.hstack((probs_claim, probs_con_stat, probs_coun_claim, probs_ev, probs_lead, probs_position, probs_rebuttal))\n",
    "\n",
    "for row in all_probs:\n",
    "    max_prob = np.max(row)\n",
    "    max_idx = np.argmax(row)\n",
    "    tag = model_dict[max_idx]\n",
    "    if max_prob < 0.5 and tag == 'Evidence':\n",
    "        row = np.delete(row, max_idx)\n",
    "        max_idx = np.argmax(row)\n",
    "        tag = model_dict[max_idx]\n",
    "\n",
    "    tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "    output_labels.append(tag)\n",
    "    \n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0098a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:13.045063Z",
     "iopub.status.busy": "2022-02-28T01:03:12.910042Z",
     "iopub.status.idle": "2022-02-28T01:03:13.388655Z",
     "shell.execute_reply": "2022-02-28T01:03:13.387495Z",
     "shell.execute_reply.started": "2022-02-27T22:56:58.672571Z"
    },
    "papermill": {
     "duration": 0.527068,
     "end_time": "2022-02-28T01:03:13.388907",
     "exception": false,
     "start_time": "2022-02-28T01:03:12.861839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead: 28462\n",
      "Rebuttal: 6619\n",
      "Claim: 55441\n",
      "Counterclaim: 7530\n",
      "Evidence: 172748\n",
      "Concluding Statement: 42204\n",
      "Position: 18220\n"
     ]
    }
   ],
   "source": [
    "print('Lead:', sum(lead_labels))\n",
    "print('Rebuttal:', sum(rebuttal_labels))\n",
    "print('Claim:', sum(claim_labels))\n",
    "print('Counterclaim:', sum(coun_claim_labels))\n",
    "print('Evidence:', sum(evidence_labels))\n",
    "print('Concluding Statement:', sum(con_stat_labels))\n",
    "print('Position:', sum(position_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c441daf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:13.490600Z",
     "iopub.status.busy": "2022-02-28T01:03:13.489639Z",
     "iopub.status.idle": "2022-02-28T01:03:39.278088Z",
     "shell.execute_reply": "2022-02-28T01:03:39.276675Z",
     "shell.execute_reply.started": "2022-02-27T22:56:59.139751Z"
    },
    "papermill": {
     "duration": 25.843307,
     "end_time": "2022-02-28T01:03:39.278300",
     "exception": false,
     "start_time": "2022-02-28T01:03:13.434993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "correct_labels = 0\n",
    "for index, row in train_data.iterrows():\n",
    "    lines = sent_tokenizer.tokenize(row['discourse_text'])\n",
    "    for line in lines:\n",
    "        #print(line, row['discourse_type'], output_labels[index])\n",
    "        if output_labels[index] == row['discourse_type']:\n",
    "            correct_labels += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbba314a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:39.372934Z",
     "iopub.status.busy": "2022-02-28T01:03:39.371860Z",
     "iopub.status.idle": "2022-02-28T01:03:39.379068Z",
     "shell.execute_reply": "2022-02-28T01:03:39.379608Z",
     "shell.execute_reply.started": "2022-02-27T22:57:23.894408Z"
    },
    "papermill": {
     "duration": 0.056793,
     "end_time": "2022-02-28T01:03:39.379832",
     "exception": false,
     "start_time": "2022-02-28T01:03:39.323039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3340609376132164"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_labels/len(output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89b6bf31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:03:39.476282Z",
     "iopub.status.busy": "2022-02-28T01:03:39.475520Z",
     "iopub.status.idle": "2022-02-28T01:04:03.122718Z",
     "shell.execute_reply": "2022-02-28T01:04:03.121919Z",
     "shell.execute_reply.started": "2022-02-27T22:57:23.901816Z"
    },
    "papermill": {
     "duration": 23.696461,
     "end_time": "2022-02-28T01:04:03.122893",
     "exception": false,
     "start_time": "2022-02-28T01:03:39.426432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of labels is 331224\n",
      "Length of inputs is 331224\n",
      "Length of IDs is 331224\n"
     ]
    }
   ],
   "source": [
    "len(output_labels)\n",
    "print(\"Length of labels is \" + str(len(output_labels)))\n",
    "# train_data.discourse_text\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "all_lines = []\n",
    "essay_ids = []\n",
    "for index, row in train_data.iterrows():\n",
    "    lines = sent_tokenizer.tokenize(row['discourse_text'])\n",
    "    essay_id = row['id']\n",
    "    for line in lines:\n",
    "        all_lines.append(line)\n",
    "        essay_ids.append(essay_id)\n",
    "        \n",
    "print(\"Length of inputs is \" + str(len(all_lines)))\n",
    "print(\"Length of IDs is \" + str(len(essay_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5882a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:04:03.247112Z",
     "iopub.status.busy": "2022-02-28T01:04:03.245945Z",
     "iopub.status.idle": "2022-02-28T01:04:03.249877Z",
     "shell.execute_reply": "2022-02-28T01:04:03.249295Z",
     "shell.execute_reply.started": "2022-02-28T00:37:00.278287Z"
    },
    "papermill": {
     "duration": 0.080071,
     "end_time": "2022-02-28T01:04:03.250058",
     "exception": false,
     "start_time": "2022-02-28T01:04:03.169987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_predict(test_features):\n",
    "    '''\n",
    "    docstring\n",
    "    '''\n",
    "    \n",
    "    test_claim = lr_claim.predict_proba(test_features)\n",
    "    probs_claim_t = test_claim[:,lr_claim.classes_ == 1]\n",
    "\n",
    "    test_con = lr_con_stat.predict_proba(test_features)\n",
    "    probs_con_stat_t = test_con[:,lr_con_stat.classes_ == 1]\n",
    "\n",
    "    test_coun_claim = lr_coun_claim.predict_proba(test_features)\n",
    "    probs_coun_claim_t = test_coun_claim[:,lr_coun_claim.classes_ == 1]\n",
    "\n",
    "    test_ev = lr_ev.predict_proba(test_features)\n",
    "    probs_ev_t = test_ev[:,lr_ev.classes_ == 1]\n",
    "\n",
    "    test_lead = lr_lead.predict_proba(test_features)\n",
    "    probs_lead_t = test_lead[:,lr_lead.classes_ == 1]\n",
    "\n",
    "    test_position = lr_position.predict_proba(test_features)\n",
    "    probs_position_t = test_position[:,lr_position.classes_ == 1]\n",
    "\n",
    "    test_rebuttal = lr_rebuttal.predict_proba(test_features)\n",
    "    probs_rebuttal_t = test_rebuttal[:,lr_rebuttal.classes_ == 1]\n",
    "\n",
    "    tag_dict = {0: 'Claim', 1: 'Concluding Statement', 2: 'Counterclaim', 3: 'Evidence', 4: 'Lead', 5: 'Position', 6:'Rebuttal'}\n",
    "    test_labels = []\n",
    "\n",
    "    test_probs = np.hstack((probs_claim_t, probs_con_stat_t, probs_coun_claim_t, probs_ev_t, probs_lead_t, probs_position_t, probs_rebuttal_t))\n",
    "\n",
    "    for row in test_probs:\n",
    "        max_prob = np.max(row)\n",
    "        max_idx = np.argmax(row)\n",
    "        tag = tag_dict[max_idx]\n",
    "        if max_prob < 0.5 and tag == 'Evidence':\n",
    "            row = np.delete(row, max_idx)\n",
    "            max_idx = np.argmax(row)\n",
    "            tag = tag_dict[max_idx]\n",
    "\n",
    "        test_labels.append(tag)\n",
    "    \n",
    "    return test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f044e43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:04:03.344688Z",
     "iopub.status.busy": "2022-02-28T01:04:03.343993Z",
     "iopub.status.idle": "2022-02-28T01:04:03.348900Z",
     "shell.execute_reply": "2022-02-28T01:04:03.349694Z",
     "shell.execute_reply.started": "2022-02-27T22:57:46.792516Z"
    },
    "papermill": {
     "duration": 0.054308,
     "end_time": "2022-02-28T01:04:03.349916",
     "exception": false,
     "start_time": "2022-02-28T01:04:03.295608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_predictionstring(text, incr):\n",
    "    '''\n",
    "    A function to strip the punction and create punctuation string\n",
    "    '''\n",
    "    split_text = text.split()\n",
    "    prediction_string = []\n",
    "    for word in split_text:\n",
    "        prediction_string.append(str(incr))\n",
    "        incr += 1\n",
    "    prediction_string = \" \".join(prediction_string)\n",
    "    return prediction_string, incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ece4cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:04:03.445048Z",
     "iopub.status.busy": "2022-02-28T01:04:03.444201Z",
     "iopub.status.idle": "2022-02-28T01:04:03.452718Z",
     "shell.execute_reply": "2022-02-28T01:04:03.453339Z",
     "shell.execute_reply.started": "2022-02-28T00:53:40.378274Z"
    },
    "papermill": {
     "duration": 0.057518,
     "end_time": "2022-02-28T01:04:03.453565",
     "exception": false,
     "start_time": "2022-02-28T01:04:03.396047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_submission(all_lines, essay_ids, output_labels):\n",
    "    list_dicts = []\n",
    "    building_text = ''\n",
    "    incr = 0\n",
    "    for idx, line in enumerate(all_lines):\n",
    "        label = output_labels[idx]\n",
    "        essay_id = essay_ids[idx]\n",
    "        if incr == 0:\n",
    "            prev_label = label\n",
    "            prev_id = essay_id\n",
    "            building_text += line\n",
    "            incr = 1\n",
    "            continue\n",
    "        if label == prev_label and essay_id == prev_id:\n",
    "            building_text += line\n",
    "            prev_label = label\n",
    "            prev_id = essay_id\n",
    "        else:\n",
    "            prediction_string, new_incr = create_predictionstring(building_text, incr)\n",
    "            list_dicts.append({'id': prev_id, 'class': prev_label, 'original text': building_text, 'predictionstring': prediction_string})\n",
    "            if essay_id != prev_id:\n",
    "                incr = 0\n",
    "            else:\n",
    "                incr = new_incr\n",
    "                prev_label = label\n",
    "                building_text = line\n",
    "    return list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef6647e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:04:03.548680Z",
     "iopub.status.busy": "2022-02-28T01:04:03.547898Z",
     "iopub.status.idle": "2022-02-28T01:04:10.231227Z",
     "shell.execute_reply": "2022-02-28T01:04:10.230463Z",
     "shell.execute_reply.started": "2022-02-27T22:57:46.816639Z"
    },
    "papermill": {
     "duration": 6.732352,
     "end_time": "2022-02-28T01:04:10.231421",
     "exception": false,
     "start_time": "2022-02-28T01:04:03.499069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_dicts = build_submission(all_lines, essay_ids, output_labels)\n",
    "submission = pd.DataFrame(data=list_dicts)\n",
    "submission.to_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52228d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T01:04:10.326647Z",
     "iopub.status.busy": "2022-02-28T01:04:10.325602Z",
     "iopub.status.idle": "2022-02-28T01:04:10.428247Z",
     "shell.execute_reply": "2022-02-28T01:04:10.429277Z",
     "shell.execute_reply.started": "2022-02-28T00:54:12.626967Z"
    },
    "papermill": {
     "duration": 0.152588,
     "end_time": "2022-02-28T01:04:10.429642",
     "exception": false,
     "start_time": "2022-02-28T01:04:10.277054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1_dicts = build_submission(test1[2], test1[1], test_predict(test_binary(test1[0])))\n",
    "test1_sub = pd.DataFrame(data=test1_dicts)\n",
    "\n",
    "test2_dicts = build_submission(test2[2], test2[1], test_predict(test_binary(test2[0])))\n",
    "test2_sub = pd.DataFrame(data=test2_dicts)\n",
    "\n",
    "test3_dicts = build_submission(test3[2], test3[1], test_predict(test_binary(test3[0])))\n",
    "test3_sub = pd.DataFrame(data=test3_dicts)\n",
    "\n",
    "test4_dicts = build_submission(test4[2], test4[1], test_predict(test_binary(test4[0])))\n",
    "test4_sub = pd.DataFrame(data=test4_dicts)\n",
    "\n",
    "test5_dicts = build_submission(test5[2], test5[1], test_predict(test_binary(test5[0])))\n",
    "test5_sub = pd.DataFrame(data=test5_dicts)\n",
    "\n",
    "test_cat = pd.concat([test1_sub, test2_sub, test3_sub, test4_sub, test5_sub], ignore_index = True)\n",
    "test_cat.drop(columns = ['original text'], inplace = True)\n",
    "\n",
    "test_cat.to_csv('/kaggle/working/test_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 504.402202,
   "end_time": "2022-02-28T01:04:12.341827",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-28T00:55:47.939625",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
